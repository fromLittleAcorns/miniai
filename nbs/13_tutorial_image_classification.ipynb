{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52897847-09e8-4174-bdd5-a516e27c8975",
   "metadata": {},
   "source": [
    "### Tutorial covering using Miniai for Image Classification\n",
    "\n",
    "This tutorial covers how to use the miniai library for image classification.  It begins with Mnist and then moves to the Imagenet Tiny.  The evolution of the models includes the use of data augmentation techniques.  Starting with Fashion Mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287de3fb-b056-4058-a0f6-0b323ac526e2",
   "metadata": {},
   "source": [
    "### Import Libraies and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd5b6c8-60c4-439b-bf79-54180f3b3f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle,gzip,math,os,time,shutil,torch,matplotlib as mpl,numpy as np,matplotlib.pyplot as plt\n",
    "import fastcore.all as fc\n",
    "from collections.abc import Mapping\n",
    "from pathlib import Path\n",
    "from operator import attrgetter,itemgetter\n",
    "from functools import partial\n",
    "from copy import copy\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import torchvision.transforms.functional as TF,torch.nn.functional as F\n",
    "from torch import tensor,nn,optim\n",
    "from torch.utils.data import DataLoader,default_collate\n",
    "from torch.nn import init\n",
    "from torch.optim import lr_scheduler\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "from datasets import load_dataset,load_dataset_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3828ed-ed77-457d-a478-2ecab52c4f28",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Callback' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mminiai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m append_stats, ActivationStatsCB\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mminiai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GeneralRelu\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mminiai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m init_weights\n",
      "File \u001b[0;32m~/git_repro/miniai/miniai/init.py:30\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GeneralRelu\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# %% ../nbs/09_Initiations.ipynb 12\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBatchTransformCB\u001b[39;00m(Callback):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, tfm, on_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, on_val\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m): fc\u001b[38;5;241m.\u001b[39mstore_attr()\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbefore_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m, learn):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Callback' is not defined"
     ]
    }
   ],
   "source": [
    "from miniai.datasets import DataLoaders, get_dls, collate_dict, inplace\n",
    "from miniai.learner import Learner, TrainLearner, MetricsCB, DeviceCB, ProgressCB, LRFinderCB\n",
    "from miniai.plotting import show_image, show_images\n",
    "from miniai.model_blocks import conv, ResBlock, lin, pre_conv\n",
    "from miniai.utils import set_seed, def_device\n",
    "from miniai.activations import append_stats, ActivationStatsCB\n",
    "from miniai.layers import GeneralRelu\n",
    "from miniai.init import init_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3787fc65-ae32-498a-acc2-6578fb2974d0",
   "metadata": {},
   "source": [
    "### Set basic parameters and defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12133b4e-1e7d-4fe5-b892-5c8f5c4c1d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
    "torch.manual_seed(1)\n",
    "mpl.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "if fc.defaults.cpus>8: fc.defaults.cpus=8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e416338-6432-4332-8cc8-cfd6fe451652",
   "metadata": {},
   "source": [
    "### Load and configure Mnist Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265633fb-5cc9-4eb8-bd9f-4cc899c09a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "xl,yl = 'image','label'\n",
    "name = \"fashion_mnist\"\n",
    "bs = 1024\n",
    "xmean,xstd = 0.28, 0.35\n",
    "\n",
    "@inplace\n",
    "def transformi(b): b[xl] = [(TF.to_tensor(o)-xmean)/xstd for o in b[xl]]\n",
    "\n",
    "dsd = load_dataset(name)\n",
    "tds = dsd.with_transform(transformi)\n",
    "dls = DataLoaders.from_dd(tds, bs, num_workers=fc.defaults.cpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de187448-d63a-4a95-8e82-155a217e4d3d",
   "metadata": {},
   "source": [
    "### Prepare Model callbacks, initialization, progress monitoring and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737dec42-0152-4e95-9378-839c918cb6cc",
   "metadata": {},
   "source": [
    "Load the callback to capture activations during training.  In this case the module filter is set to GeneralRelu, which means that activations will be captured for every instance of that in the model. As an alternative the \"mods\" parameter can be used to define a list of layers for which activations will be captured.  This might be more appropriate for larger models to prevent activations from too many layers being captured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9909a8af-3536-48f4-bd26-8e3ee1573f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "astats = ActivationStatsCB(module_filter=fc.risinstance(GeneralRelu))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971940f2-b5a9-4c0f-91c1-55b114ce2889",
   "metadata": {},
   "source": [
    "Create a callback fo capture metrics during training.  In this case Multiclass accuracy.  Additional metrics can be created and assigned using keyword arguments.  Any metric defined using TorchEval should work.  In addition the metrics could be supplied in a list (without the keyword argument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe755a3-eaf1-4a00-988e-e03f795a58a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = MetricsCB(accuracy=MulticlassAccuracy())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e48d6846-3791-4850-85ef-5b814edd5c6e",
   "metadata": {},
   "source": [
    "Add a callback to select the appropriate device for calculation. If a GPU is present it will automatically select it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfebaa3-f0cc-458a-a5f8-675afa3dd203",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_cb = DeviceCB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27a93a4-c1ae-420c-9109-e5860ddaa9a3",
   "metadata": {},
   "source": [
    "Add a progress callback to print out and, optionally, plot training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562b81a3-09e4-4576-a779-93b135926789",
   "metadata": {},
   "outputs": [],
   "source": [
    "progrss_cb = ProgressCB(plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34812f8a-4d06-4e79-9460-034c59094443",
   "metadata": {},
   "source": [
    "Create a list of the callbacks to be used in the model.  Others can be added if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c09380-755a-45ad-89ee-c530ccd5c524",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = [device_cb, metrics, progrss_cb, astats]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483572b7-586e-421d-ad8e-501fb4ab96b2",
   "metadata": {},
   "source": [
    "Create a activation function based on the GeneralRelu with predefined values for leak and sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df12446f-0652-4aae-abba-c9a9346ca3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_gr = partial(GeneralRelu, leak=0.1, sub=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa97a09-23c9-4392-b95a-33b6e9c15f43",
   "metadata": {},
   "source": [
    "Define an initialisation function.  This will be applied to any conv layer and will assign a Kaiming normal initialisation using the value for leaky define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d665db6-278f-4eb5-baa9-e0577257beea",
   "metadata": {},
   "outputs": [],
   "source": [
    "iw = partial(init_weights, leaky=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34b0777-0221-48ac-a392-b50be74c8cd9",
   "metadata": {},
   "source": [
    "Create a function to generate a ResNet style model using ResBlocks.  The ResBlocks have a conv block containing two conv layers, with the first conv block changing the number of channels and the second the resolution (if required).  Activations is by default only applied to the output form the first conv block.\n",
    "\n",
    "As well as the conv block the ResBlock also has a pass through path that uses a pooling layer (if the resolution needs to be changed) and a conv layer (if the nuber of channels needs to change). After the outputs from the pass through path and the conv block are combined an optional activation can be applied\n",
    "\n",
    "In the function below blocks are stacked with progressively increasing numbers of channels (if the defaults are used).  By default BatchNorm2d is used for normalisation, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14c8059-dbc5-4298-8c9a-ec4470682493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(act=nn.ReLU, nfs=(8, 16, 32, 64, 128, 256), norm=nn.BatchNorm2d):\n",
    "    layers = [ResBlock(1, nfs[0], stride=1, act=act, norm=norm)]\n",
    "    layers += [ResBlock(nfs[i], nfs[i+1], stride=2, act=act, norm=norm) for i in range(len(nfs)-1)]\n",
    "    layers += [nn.Flatten(), nn.Linear(nfs[-1], 10, bias=False), nn.BatchNorm1d(10)]\n",
    "    return nn.Sequential(*layers).to(def_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4354a6-1fbf-4fda-8ac2-63e576ac7924",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(act=act_gr, norm=nn.BatchNorm2d).apply(iw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c878129d-9afe-459b-b206-6d756bc2b7cd",
   "metadata": {},
   "source": [
    "Create a learner using the callbacks and model created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29bf214-1210-4f52-bcf2-aba338a54eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(model=model, dls=dls, loss_func=F.cross_entropy, lr=0.001, cbs=cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a3bc9e-335d-466b-ab4d-575a6a4472fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e013ea-9672-48ab-a567-19daa57215f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
