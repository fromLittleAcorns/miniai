[
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "source\n\nsay_hello\n\n say_hello (to)\n\nSay hello to somebody\n\nassert say_hello(\"John\") == \"Hello John!\"\n\n\ntest_eq(say_hello(\"John\"), \"Hello John!\")\n\n\nsource\n\n\nfoo\n\n foo ()"
  },
  {
    "objectID": "datasets.html",
    "href": "datasets.html",
    "title": "Datasets",
    "section": "",
    "text": "import logging,pickle,gzip,os,time,shutil,torch,matplotlib as mpl\nfrom pathlib import Path\nimport torch\nfrom torch import tensor,nn,optim\nimport torch.nn.functional as F\nfrom datasets import load_dataset,load_dataset_builder\n\nimport torchvision.transforms.functional as TF\nfrom fastcore.test import test_close, equals\nfrom nbdev import show_doc\n\n/Users/johnrichmond/miniconda/envs/miniai/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\ntorch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\ntorch.manual_seed(1)\nmpl.rcParams['image.cmap'] = 'gray'\nlogging.disable(logging.WARNING)\nThe dataset management will be developed and demonstrated using databases from Huggingface, but can be readily adapted to work with other datasets."
  },
  {
    "objectID": "datasets.html#hugging-face-datasets",
    "href": "datasets.html#hugging-face-datasets",
    "title": "Datasets",
    "section": "Hugging Face Datasets",
    "text": "Hugging Face Datasets\nNote that a list of the available datasets can be found on the Hugging Face hub:\nHugging Face Hub\nHugging Face datasets have a dictionary based structure\n\nname = \"fashion_mnist\"\nds_builder = load_dataset_builder(name)\nprint(ds_builder.info.description)\n\nFashion-MNIST is a dataset of Zalando's article images—consisting of a training set of\n60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image,\nassociated with a label from 10 classes. We intend Fashion-MNIST to serve as a direct drop-in\nreplacement for the original MNIST dataset for benchmarking machine learning algorithms.\nIt shares the same image size and structure of training and testing splits.\n\n\n\nThe dataset builder has a number of useful properties that can help better understand a dataset. These are mostly sub properties the info attribute and include: - features - splits - homepage\nAnd lots of other useful things.\nDataset builder allows obtaining details about he dataset without actually downloading it. Accessing the dataset then uses the load_dataet mehod\n\nds_builder.info.features\n\n{'image': Image(decode=True, id=None),\n 'label': ClassLabel(names=['T - shirt / top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'], id=None)}\n\n\n\nds_builder.info.splits\n\n{'train': SplitInfo(name='train', num_bytes=31296607, num_examples=60000, shard_lengths=None, dataset_name='fashion_mnist'),\n 'test': SplitInfo(name='test', num_bytes=5233810, num_examples=10000, shard_lengths=None, dataset_name='fashion_mnist')}\n\n\n\nds_builder.info.homepage\n\n'https://github.com/zalandoresearch/fashion-mnist'\n\n\nThe load_dataset function can be used to load the whole dataset, which can then be sub divided if necessary\n\nds_loader = load_dataset(name)\n\n100%|████████████████████████████████████████████| 2/2 [00:00&lt;00:00, 332.45it/s]\n\n\nThe different splits can then be assigned separately\n\ntrain_ds, test_ds = ds_loader['train'], ds_loader['test']\n\nRetireving individual items can be done using the dataset features, in this case the image and label\n\ntrain_ds[0]\n\n{'image': &lt;PIL.PngImagePlugin.PngImageFile image mode=L size=28x28&gt;,\n 'label': 9}\n\n\n\ntrain_ds[0]['image']\n\n\n\n\nThis can be simplified by assigning the features (keys) to x and y\n\nx, y = ds_builder.info.features\nx, y\n\n('image', 'label')\n\n\n\nimg = train_ds[0][x]\nimg\n\n\n\n\n\nsource\n\ninplace\n\n inplace (f)\n\nThis function allows a function that does not return anything directly (ie one that modifies things without a return statenent) to then be used in an application that required a return. So this function is a wrapper of another function that simply executes the function and then returns the modified input\nTest that the inline function does as it should\n\n@inplace\ndef torch_cos(x):\n    # Modify in place x to become cos(x)\n    torch.cos_(x)\n\n\nangle = torch.tensor(torch.pi/8)\ny = torch_cos(angle)\nequals(y, torch.cos(torch.tensor(torch.pi/8)))\n\nTrue\n\n\nThe HuggingFace dataset provides datasets that return a dictionary of features. It also provides the capability to apply transforms to the dataset items using the with_transforms method. In the case of the Fashion Mnist dataset it is convenient to be able to return the inputs and targets as flattened tensors. This can be done using a function to convert items to tensors and then flatten them, followed by a collation function that will build upon the default_collate function from Pytorch\n\n@inplace\ndef transformi(b): b[x] = [torch.flatten(TF.to_tensor(o)) for o in b[x]]\n\nTo illustrate how default_collate will deal with a dict see the following\n\nbatch = dict(a=[1],b=[2]), dict(a=[3],b=[4])\ndefault_collate(batch)\n\n{'a': [tensor([1, 3])], 'b': [tensor([2, 4])]}\n\n\n\n# create a dataset that will apply the transformi function to the items it returns\ntsds = train_ds.with_transform(transformi)\n\n\ntrain_ds[0]\n\n{'image': &lt;PIL.PngImagePlugin.PngImageFile image mode=L size=28x28&gt;,\n 'label': 9}\n\n\n\ntsds[0]\n\n{'image': tensor([0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.05, 0.29, 0.00, 0.00, 0.00, 0.02, 0.00, 0.00, 0.00, 0.00, 0.00,\n         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.01, 0.00, 0.14, 0.53, 0.50, 0.24, 0.21, 0.00,\n         0.00, 0.00, 0.00, 0.01, 0.02, 0.00, 0.00, 0.01, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.02, 0.00,\n         0.40, 0.80, 0.69, 0.53, 0.56, 0.48, 0.09, 0.00, 0.00, 0.00, 0.00, 0.05, 0.04, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.61, 0.93, 0.81, 0.70, 0.42, 0.61, 0.63, 0.43, 0.25, 0.09, 0.30, 0.51, 0.28, 0.06, 0.00, 0.00,\n         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.27, 0.81, 0.87, 0.85, 0.85, 0.85, 0.64, 0.50, 0.47, 0.48, 0.57,\n         0.55, 0.35, 0.67, 0.26, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.78, 0.91, 0.91, 0.91, 0.90,\n         0.87, 0.87, 0.84, 0.84, 0.64, 0.50, 0.48, 0.77, 0.90, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n         0.00, 0.72, 0.88, 0.85, 0.87, 0.89, 0.92, 0.89, 0.88, 0.87, 0.88, 0.87, 0.87, 0.96, 0.68, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.76, 0.89, 0.85, 0.84, 0.78, 0.71, 0.83, 0.82, 0.83, 0.84, 0.87, 0.86, 0.95, 0.79, 0.00,\n         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.01, 0.00, 0.05, 0.86, 0.86, 0.83, 0.85, 0.75, 0.66, 0.89, 0.82, 0.85,\n         0.88, 0.83, 0.89, 0.77, 0.82, 0.20, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.02, 0.00, 0.39, 0.96, 0.87, 0.86,\n         0.85, 0.80, 0.78, 0.87, 0.84, 0.84, 0.87, 0.86, 0.96, 0.47, 0.65, 0.22, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.02,\n         0.00, 0.00, 0.22, 0.93, 0.89, 0.90, 0.89, 0.94, 0.91, 0.84, 0.85, 0.87, 0.92, 0.85, 0.85, 0.82, 0.36, 0.00, 0.00, 0.00, 0.00, 0.02,\n         0.02, 0.03, 0.01, 0.00, 0.00, 0.00, 0.00, 0.00, 0.93, 0.89, 0.85, 0.87, 0.87, 0.86, 0.87, 0.87, 0.85, 0.87, 0.90, 0.84, 0.85, 1.00,\n         0.30, 0.00, 0.00, 0.01, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.24, 0.57, 0.80, 0.89, 0.81, 0.84, 0.87, 0.85, 0.82, 0.83, 0.85,\n         0.88, 0.87, 0.86, 0.84, 0.88, 0.96, 0.62, 0.00, 0.00, 0.00, 0.00, 0.00, 0.07, 0.17, 0.32, 0.42, 0.74, 0.89, 0.86, 0.87, 0.85, 0.89,\n         0.78, 0.80, 0.83, 0.90, 0.88, 0.92, 0.69, 0.74, 0.98, 0.97, 0.91, 0.93, 0.84, 0.00, 0.00, 0.22, 0.73, 0.82, 0.88, 0.87, 0.88, 0.82,\n         0.80, 0.84, 0.82, 0.82, 0.78, 0.62, 0.96, 0.76, 0.81, 0.87, 1.00, 1.00, 0.87, 0.92, 0.87, 0.83, 0.86, 0.91, 0.96, 0.00, 0.01, 0.79,\n         0.89, 0.88, 0.87, 0.83, 0.83, 0.84, 0.80, 0.80, 0.80, 0.86, 0.94, 0.31, 0.59, 1.00, 0.90, 0.87, 0.74, 0.60, 0.75, 0.82, 0.80, 0.82,\n         0.87, 0.89, 0.88, 0.00, 0.38, 0.91, 0.78, 0.82, 0.87, 0.90, 0.90, 0.92, 0.98, 0.86, 0.76, 0.84, 0.85, 0.95, 0.25, 0.29, 0.42, 0.46,\n         0.66, 0.86, 0.87, 0.84, 0.85, 0.87, 0.87, 0.88, 0.90, 0.11, 0.29, 0.80, 0.83, 0.80, 0.76, 0.80, 0.83, 0.88, 0.85, 0.73, 0.77, 0.81,\n         0.78, 0.84, 0.94, 0.76, 0.89, 0.96, 0.94, 0.87, 0.85, 0.83, 0.82, 0.87, 0.86, 0.87, 0.90, 0.26, 0.19, 0.80, 0.72, 0.76, 0.84, 0.77,\n         0.73, 0.75, 0.76, 0.75, 0.79, 0.84, 0.86, 0.87, 0.86, 0.93, 0.88, 0.85, 0.78, 0.81, 0.73, 0.71, 0.69, 0.67, 0.71, 0.80, 0.81, 0.45,\n         0.00, 0.48, 0.86, 0.76, 0.70, 0.67, 0.72, 0.77, 0.80, 0.82, 0.84, 0.81, 0.83, 0.82, 0.78, 0.77, 0.76, 0.75, 0.76, 0.75, 0.78, 0.75,\n         0.69, 0.61, 0.65, 0.69, 0.82, 0.36, 0.00, 0.00, 0.29, 0.74, 0.83, 0.75, 0.69, 0.67, 0.69, 0.71, 0.73, 0.74, 0.74, 0.74, 0.76, 0.78,\n         0.80, 0.82, 0.82, 0.82, 0.83, 0.74, 0.74, 0.76, 0.75, 0.85, 0.67, 0.00, 0.01, 0.00, 0.00, 0.00, 0.26, 0.78, 0.87, 0.93, 0.94, 0.95,\n         0.96, 0.95, 0.96, 0.87, 0.86, 0.76, 0.75, 0.70, 0.71, 0.71, 0.71, 0.69, 0.65, 0.66, 0.39, 0.23, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n         0.00, 0.00, 0.00, 0.16, 0.24, 0.17, 0.28, 0.16, 0.14, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00,\n         0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00]),\n 'label': 9}\n\n\nThe dictionary aspects of this are not needed and so the collate_dict function that follows extracts the individual items of the batch and returns then as a tuple of the input and output tensors\n\nsource\n\n\ncollate_dict\n\n collate_dict (ds)\n\nwhen a dataset is defined by a dictionary this will identify the features and split into inputs and outputs as tensor arrays ready for input to a model\nNote that it is necessary initialise the collate_dict function supplied to the dataloader with the dataset. This is necessary so that the embeded get function can identify the features to be loaded. It would be nice if this could be avoided\n\ntrain_dl = DataLoader(tsds, batch_size=4, shuffle=True, collate_fn=collate_dict(tsds))\n\n\nxb, yb = next(iter(train_dl))\n\n\nxb.shape, yb.shape\n\n(torch.Size([4, 784]), torch.Size([4]))\n\n\n\ndef collate_dict2(batch):\n    pairs = default_collate(batch)\n    items = [values for values in pairs.values()]\n    return items\n\n\ntrain_dl2 = DataLoader(tsds, batch_size=4, shuffle=True, collate_fn=collate_dict2)\n\n\nxb, yb = next(iter(train_dl2))\n\n\nxb.shape, yb.shape\n\n(torch.Size([4, 784]), torch.Size([4]))\n\n\n\n\nAdd Basic DataLoader Helper Functions\n\nsource\n\n\nget_dls\n\n get_dls (train_ds, valid_ds, bs=64, **kwargs)\n\nUtility function to return train and validation dataloaders from two datasets\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntrain_ds\n\n\nTraining Dataset\n\n\nvalid_ds\n\n\nValidation Dataset\n\n\nbs\nint\n64\nBatch size (int)\n\n\nkwargs\n\n\n\n\n\n\n\nsource\n\n\nDataLoaders\n\n DataLoaders (*dls)\n\nConvenience class to create and contain a collection of datasets"
  },
  {
    "objectID": "03_utils.html",
    "href": "03_utils.html",
    "title": "Utilities",
    "section": "",
    "text": "General purpose utilities including setting device, moving data and models to devices, setting seed\nsource"
  },
  {
    "objectID": "03_utils.html#test-random-number-generation",
    "href": "03_utils.html#test-random-number-generation",
    "title": "Utilities",
    "section": "Test random number generation",
    "text": "Test random number generation\nGenerate random number after seed, reapply seed, regenerate numbers and check equal\n\nset_seed(42)\nrand_num_1 = random.randint(1, 1000)\ntorch_num_1 = torch.randint(1, 1000, (1,))\nnp_num_1 = np.random.randint(0, 1000, (1,))\nset_seed(42)\nrand_num_2 = random.randint(1, 1000)\ntorch_num_2 = torch.randint(1, 1000, (1,))\nnp_num_2 = np.random.randint(0, 1000, (1,))\n\nfct.equals(rand_num_1, rand_num_2)\nfct.equals(torch_num_1, torch_num_1)\nfct.equals(np_num_1, np_num_2)"
  },
  {
    "objectID": "plotting.html",
    "href": "plotting.html",
    "title": "Plotting",
    "section": "",
    "text": "from miniai.datasets import inplace, collate_dict\ntorch.manual_seed(1)\nmpl.rcParams['image.cmap'] = 'gray_r'"
  },
  {
    "objectID": "plotting.html#plotting",
    "href": "plotting.html#plotting",
    "title": "Plotting",
    "section": "Plotting",
    "text": "Plotting\n\nSingle Images\n/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Other Parameters\n  else: warn(msg)\n/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section See Also\n  else: warn(msg)\n/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Notes\n  else: warn(msg)\n\nsource\n\n\nshow_image\n\n show_image (img, ax=None, title=None, noframe=True, figsize=None,\n             cmap=None, norm=None, aspect=None, interpolation=None,\n             alpha=None, vmin=None, vmax=None, origin=None, extent=None,\n             interpolation_stage=None, filternorm=True, filterrad=4.0,\n             resample=None, url=None, data=None)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nimg\n\n\n\n\n\nax\nNoneType\nNone\n\n\n\ntitle\nNoneType\nNone\n\n\n\nnoframe\nbool\nTrue\n\n\n\nfigsize\nNoneType\nNone\n\n\n\ncmap\nNoneType\nNone\nThe Colormap instance or registered colormap name used to map scalar datato colors.This parameter is ignored if X is RGB(A).\n\n\nnorm\nNoneType\nNone\nThe normalization method used to scale scalar data to the [0, 1] rangebefore mapping to colors using cmap. By default, a linear scaling isused, mapping the lowest value to 0 and the highest to 1.If given, this can be one of the following:- An instance of .Normalize or one of its subclasses (see :doc:/tutorials/colors/colormapnorms).- A scale name, i.e. one of “linear”, “log”, “symlog”, “logit”, etc. For a list of available scales, call matplotlib.scale.get_scale_names(). In that case, a suitable .Normalize subclass is dynamically generated and instantiated.This parameter is ignored if X is RGB(A).\n\n\naspect\nNoneType\nNone\nThe aspect ratio of the Axes. This parameter is particularlyrelevant for images since it determines whether data pixels aresquare.This parameter is a shortcut for explicitly calling.Axes.set_aspect. See there for further details.- ‘equal’: Ensures an aspect ratio of 1. Pixels will be square (unless pixel sizes are explicitly made non-square in data coordinates using extent).- ‘auto’: The Axes is kept fixed and the aspect is adjusted so that the data fit in the Axes. In general, this will result in non-square pixels.\n\n\ninterpolation\nNoneType\nNone\nThe interpolation method used.Supported values are ‘none’, ‘antialiased’, ‘nearest’, ‘bilinear’,‘bicubic’, ‘spline16’, ‘spline36’, ‘hanning’, ‘hamming’, ‘hermite’,‘kaiser’, ‘quadric’, ‘catrom’, ‘gaussian’, ‘bessel’, ‘mitchell’,‘sinc’, ‘lanczos’, ‘blackman’.The data X is resampled to the pixel size of the image on thefigure canvas, using the interpolation method to either up- ordownsample the data.If interpolation is ‘none’, then for the ps, pdf, and svgbackends no down- or upsampling occurs, and the image data ispassed to the backend as a native image. Note that different ps,pdf, and svg viewers may display these raw pixels differently. Onother backends, ‘none’ is the same as ‘nearest’.If interpolation is the default ‘antialiased’, then ‘nearest’interpolation is used if the image is upsampled by more than afactor of three (i.e. the number of display pixels is at leastthree times the size of the data array). If the upsampling rate issmaller than 3, or the image is downsampled, then ‘hanning’interpolation is used to act as an anti-aliasing filter, unless theimage happens to be upsampled by exactly a factor of two or one.See:doc:/gallery/images_contours_and_fields/interpolation_methodsfor an overview of the supported interpolation methods, and:doc:/gallery/images_contours_and_fields/image_antialiasing fora discussion of image antialiasing.Some interpolation methods require an additional radius parameter,which can be set by filterrad. Additionally, the antigrain imageresize filter is controlled by the parameter filternorm.\n\n\nalpha\nNoneType\nNone\nThe alpha blending value, between 0 (transparent) and 1 (opaque).If alpha is an array, the alpha blending values are applied pixelby pixel, and alpha must have the same shape as X.\n\n\nvmin\nNoneType\nNone\n\n\n\nvmax\nNoneType\nNone\n\n\n\norigin\nNoneType\nNone\nPlace the [0, 0] index of the array in the upper left or lowerleft corner of the Axes. The convention (the default) ‘upper’ istypically used for matrices and images.Note that the vertical axis points upward for ‘lower’but downward for ‘upper’.See the :doc:/tutorials/intermediate/imshow_extent tutorial forexamples and a more detailed description.\n\n\nextent\nNoneType\nNone\nThe bounding box in data coordinates that the image will fill.These values may be unitful and match the units of the Axes.The image is stretched individually along x and y to fill the box.The default extent is determined by the following conditions.Pixels have unit size in data coordinates. Their centers are oninteger coordinates, and their center coordinates range from 0 tocolumns-1 horizontally and from 0 to rows-1 vertically.Note that the direction of the vertical axis and thus the defaultvalues for top and bottom depend on origin:- For origin == 'upper' the default is (-0.5, numcols-0.5, numrows-0.5, -0.5).- For origin == 'lower' the default is (-0.5, numcols-0.5, -0.5, numrows-0.5).See the :doc:/tutorials/intermediate/imshow_extent tutorial forexamples and a more detailed description.\n\n\ninterpolation_stage\nNoneType\nNone\nIf ‘data’, interpolationis carried out on the data provided by the user. If ‘rgba’, theinterpolation is carried out after the colormapping has beenapplied (visual interpolation).\n\n\nfilternorm\nbool\nTrue\nA parameter for the antigrain image resize filter (see theantigrain documentation). If filternorm is set, the filternormalizes integer values and corrects the rounding errors. Itdoesn’t do anything with the source floating point values, itcorrects only integers according to the rule of 1.0 which meansthat any sum of pixel weights must be equal to 1.0. So, thefilter function must produce a graph of the proper shape.\n\n\nfilterrad\nfloat\n4.0\nThe filter radius for filters that have a radius parameter, i.e.when interpolation is one of: ‘sinc’, ‘lanczos’ or ‘blackman’.\n\n\nresample\nNoneType\nNone\nWhen True, use a full resampling method. When False, onlyresample when the output image is larger than the input image.\n\n\nurl\nNoneType\nNone\nSet the url of the created .AxesImage. See .Artist.set_url.\n\n\ndata\nNoneType\nNone\n\n\n\n\nNote that the fastcore library gives a list of all of the parameters that can be passed as kwargs, for example interpolation.|\n\nhelp(show_image)\n\nHelp on function show_image in module __main__:\n\nshow_image(img, ax=None, title=None, noframe=True, figsize=None, *, cmap=None, norm=None, aspect=None, interpolation=None, alpha=None, vmin=None, vmax=None, origin=None, extent=None, interpolation_stage=None, filternorm=True, filterrad=4.0, resample=None, url=None, data=None)\n    #|export\n\n\n\n\nLoad the Fashion Mnist dataset to provide some example images\n\nds_loader = load_dataset(\"fashion_mnist\")\ntrain_ds, test_ds = ds_loader['train'], ds_loader['test']\n\nFound cached dataset fashion_mnist (/Users/johnrichmond/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/0a671f063342996f19779d38c0ab4abef9c64f757b35af8134b331c294d7ba48)\n100%|████████████████████████████████████████████| 2/2 [00:00&lt;00:00, 333.66it/s]\n\n\n\ntrain_ds.features\n\n{'image': Image(decode=True, id=None),\n 'label': ClassLabel(names=['T - shirt / top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'], id=None)}\n\n\n\nlabels = train_ds.features['label']\nlabels.int2str(0)\n\n'T - shirt / top'\n\n\n\ntrain_ds[0]\n\n{'image': &lt;PIL.PngImagePlugin.PngImageFile image mode=L size=28x28&gt;,\n 'label': 9}\n\n\n\n@inplace\ndef transformi(b, key:str='image'): b[key] = [TF.to_tensor(o) for o in b[key]]\n\n\ntsds = train_ds.with_transform(transformi)\n\n\ntrain_ds[0]\n\n{'image': &lt;PIL.PngImagePlugin.PngImageFile image mode=L size=28x28&gt;,\n 'label': 9}\n\n\n\ndl=DataLoader(tsds, collate_fn=collate_dict(tsds), batch_size=16)\n\n\nxb, yb = next(iter(dl))\n\n\nxb.shape, yb.shape\n\n(torch.Size([16, 1, 28, 28]), torch.Size([16]))\n\n\nTo plot the image using matplotlib imshow requires the image to be indexed down to just the last two dimensions and doesn’t take care of removing the axes without additional commands\n\nimg = xb[0][0]\nplt.imshow(img)\n\n&lt;matplotlib.image.AxesImage&gt;\n\n\n\n\n\nUsing show_image this is much simpler\n\nshow_image(xb[0], figsize=(6,6), title=\"Example Title\");\n\n\n\n\n\n\n\nFrom single images with show_image showing multiple images\nIt is often necessary to plot multiple images in a grid. To do so effectively it is necessary to size the imaged appropriated and to only show images where one exists (ie empty spots on the grid should reamin empty. ALso we need to make sure we can add labels to each image\n\nsource\n\n\nsubplots\n\n subplots (nrows:int=1, ncols:int=1, figsize:tuple=None, imsize:float=3,\n           suptitle:str=None, sharex=False, sharey=False, squeeze=True,\n           width_ratios=None, height_ratios=None, subplot_kw=None,\n           gridspec_kw=None, **kwargs)\n\ncreate grid of axes ready for assignment of images to each axis Args: nrows (int): number of rows ncols (int): number of columns figsize (Tuple[float, float]): Size of overall figure that will be produced in default units imsize (float): size of individual images in default units suptitle (Union[str, None]): title for the overall figure\nReturns: fig: plt.Figure ax: np.array(plt.Axes)\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnrows\nint\n1\nNumber of rows\n\n\nncols\nint\n1\nNumber of columns\n\n\nfigsize\ntuple\nNone\nSize of overall figure that will be produced in default units\n\n\nimsize\nfloat\n3\nsize of individual images in default units\n\n\nsuptitle\nstr\nNone\nTitle for the plot\n\n\nsharex\nbool\nFalse\n\n\n\nsharey\nbool\nFalse\n\n\n\nsqueeze\nbool\nTrue\n\n\n\nwidth_ratios\nNoneType\nNone\n\n\n\nheight_ratios\nNoneType\nNone\n\n\n\nsubplot_kw\nNoneType\nNone\n\n\n\ngridspec_kw\nNoneType\nNone\n\n\n\nkwargs\n\n\n\n\n\nReturns\n(plt.Figure, plt.Axes)\n\n\n\n\n\nThe above function can then be used with multiple images as follows:\n\nlbls = [labels.int2str(int(y)) for y in yb[:8]]\n\n\nfig, axs = subplots(nrows=2, ncols=4, imsize=2, suptitle=\"Example of images\")\nimgs = xb[:8]\nlbls = [labels.int2str(int(y)) for y in yb[:8]]\nfor ax, img, lbl in zip(axs.flat, imgs, lbls): show_image(img, ax, title=lbl)\n\n\n\n\nThe function more intelligent by automatically calculating the size of the images and allowing the title to have weight and size defined. This function can be built on top of the subplots method above\n\nsource\n\n\nget_grid\n\n get_grid (n:int, nrows:int=None, ncols:int=None, weight:str='bold',\n           size:int=14, figsize:tuple=None, imsize:float=3,\n           suptitle:str=None, sharex=False, sharey=False, squeeze=True,\n           width_ratios=None, height_ratios=None, subplot_kw=None,\n           gridspec_kw=None)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nn\nint\n\nNumber of axes\n\n\nnrows\nint\nNone\nNumber of rows\n\n\nncols\nint\nNone\nNumber of columns\n\n\nweight\nstr\nbold\nWeight to apply to the title\n\n\nsize\nint\n14\nsize of the title font\n\n\nfigsize\ntuple\nNone\nSize of overall figure that will be produced in default units\n\n\nimsize\nfloat\n3\nsize of individual images in default units\n\n\nsuptitle\nstr\nNone\nTitle for the plot\n\n\nsharex\nbool\nFalse\n\n\n\nsharey\nbool\nFalse\n\n\n\nsqueeze\nbool\nTrue\n\n\n\nwidth_ratios\nNoneType\nNone\n\n\n\nheight_ratios\nNoneType\nNone\n\n\n\nsubplot_kw\nNoneType\nNone\n\n\n\ngridspec_kw\nNoneType\nNone\n\n\n\n\n\nfig, axs = get_grid(8, nrows=2, suptitle=\"This is a title\")\nfor ax, img, lbl in zip(axs.flat, imgs, lbls): show_image(img, ax, title=lbl)\n\n\n\n\nFinally it is possible to now create a show_images function that uses show image to display individual images and get_grid to provide the grid of axes upon which to plot them. We will also pass in the labels for each object so that this can be used as a title for each image\n\nsource\n\n\nshow_images\n\n show_images (imgs:list, nrows:int=1, ncols:int=None,\n              titles:List[str]=None, figsize:tuple=None, imsize:float=3,\n              suptitle:str=None, sharex=False, sharey=False, squeeze=True,\n              width_ratios=None, height_ratios=None, subplot_kw=None,\n              gridspec_kw=None)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nimgs\nlist\n\nList of images to show\n\n\nnrows\nint\n1\nNumber of rows\n\n\nncols\nint\nNone\nNumber of columns\n\n\ntitles\nList[str]\nNone\nlist of individual sub-plot headings\n\n\nfigsize\ntuple\nNone\nSize of overall figure that will be produced in default units\n\n\nimsize\nfloat\n3\nsize of individual images in default units\n\n\nsuptitle\nstr\nNone\nTitle for the plot\n\n\nsharex\nbool\nFalse\n\n\n\nsharey\nbool\nFalse\n\n\n\nsqueeze\nbool\nTrue\n\n\n\nwidth_ratios\nNoneType\nNone\n\n\n\nheight_ratios\nNoneType\nNone\n\n\n\nsubplot_kw\nNoneType\nNone\n\n\n\ngridspec_kw\nNoneType\nNone\n\n\n\n\n\nhelp(show_images)\n\nHelp on function show_images in module __main__:\n\nshow_images(imgs: 'list', nrows: 'int' = 1, ncols: 'int' = None, titles: 'List[str]' = None, *, figsize: 'tuple' = None, imsize: 'float' = 3, suptitle: 'str' = None, sharex=False, sharey=False, squeeze=True, width_ratios=None, height_ratios=None, subplot_kw=None, gridspec_kw=None)\n    #|export\n\n\n\n\nshow_images(imgs, suptitle=\"Main Title\", titles=lbls, imsize=2.0, nrows=3, ncols=3, cmap=\"gray_r\",\n           figsize=(10,10))"
  },
  {
    "objectID": "learner.html",
    "href": "learner.html",
    "title": "Learner",
    "section": "",
    "text": "source\n\nCancelEpochException\nCommon base class for all non-exit exceptions.\n\nsource\n\n\nCancelBatchException\nCommon base class for all non-exit exceptions.\n\nsource\n\n\nCancelFitException\nCommon base class for all non-exit exceptions.\nCallback is the superclass of all callbacks. A lower order results in earlier execution.\n\nsource\n\n\nCallback\n\n Callback ()\n\nInitialize self. See help(type(self)) for accurate signature.\nrun_cbs runs a given method for all callbacks cbs. E.g., if cbs=[cb1, cb2] and method_nm=\"after_fit\" it runs cb1.after_fit and cb2.after_fit.\n\nsource\n\n\nrun_cbs\n\n run_cbs (cbs, method_nm, learn=None)\n\n\nsource\n\n\nSingleBatchCB\n\n SingleBatchCB ()\n\nInitialize self. See help(type(self)) for accurate signature.\nMetricsCB records all metrics and the loss.\n\nsource\n\n\nMetricsCB\n\n MetricsCB (*ms, **metrics)\n\nInitialize self. See help(type(self)) for accurate signature.\nDeviceCB puts the model and each batch onto the specified device.\n\nsource\n\n\nDeviceCB\n\n DeviceCB (device='cpu')\n\nInitialize self. See help(type(self)) for accurate signature.\nTrainCB is the default implementation for predict, get_loss, backward, step and zero_grad\n\nsource\n\n\nTrainCB\n\n TrainCB (n_inp=1)\n\nInitialize self. See help(type(self)) for accurate signature.\nProgressCB display the metrics recorded via MetricsCB as table and optionally as graph. Requires MetricsCB.\n\nsource\n\n\nProgressCB\n\n ProgressCB (plot=False)\n\nInitialize self. See help(type(self)) for accurate signature.\nwith_cbs(nm) is a decorator that first run before_nm, then the function it wraps and then after_nm\n\nsource\n\n\nwith_cbs\n\n with_cbs (nm)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nsource\n\n\nLearner\n\n Learner (model, dls=(0,), loss_func=&lt;function mse_loss&gt;, lr=0.1,\n          cbs=None, opt_func=&lt;class 'torch.optim.sgd.SGD'&gt;)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nfrom datasets import load_dataset\nimport torchvision.transforms.functional as TF\nfrom torch import nn,tensor\n\nx,y = 'image','label'\nname = \"fashion_mnist\"\ndsd = load_dataset(name)\n\n@inplace\ndef transformi(b): b[x] = [torch.flatten(TF.to_tensor(o)) for o in b[x]]     \n\nbs = 1024\ntds = dsd.with_transform(transformi)\n\ndls = DataLoaders.from_dd(tds, bs, num_workers=4)\n\nm,nh = 28*28,50\nmodel = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))\n\nlearn = Learner(model, dls, cbs=[TrainCB(), DeviceCB(), MetricsCB(accuracy=MulticlassAccuracy()), ProgressCB(plot=True)], loss_func=F.cross_entropy)\n\nDownloading builder script:   0%|          | 0.00/4.83k [00:00&lt;?, ?B/s]Downloading builder script: 100%|##########| 4.83k/4.83k [00:00&lt;00:00, 17.5MB/s]\nDownloading metadata:   0%|          | 0.00/3.13k [00:00&lt;?, ?B/s]Downloading metadata: 100%|##########| 3.13k/3.13k [00:00&lt;00:00, 14.7MB/s]\nDownloading readme:   0%|          | 0.00/8.85k [00:00&lt;?, ?B/s]Downloading readme: 100%|##########| 8.85k/8.85k [00:00&lt;00:00, 23.5MB/s]\nDownloading data files:   0%|          | 0/4 [00:00&lt;?, ?it/s]\nDownloading data:   0%|          | 0.00/26.4M [00:00&lt;?, ?B/s]\nDownloading data:  10%|#         | 2.73M/26.4M [00:00&lt;00:00, 27.3MB/s]\nDownloading data:  34%|###4      | 9.08M/26.4M [00:00&lt;00:00, 48.6MB/s]\nDownloading data:  59%|#####8    | 15.5M/26.4M [00:00&lt;00:00, 55.7MB/s]\nDownloading data:  83%|########2 | 21.9M/26.4M [00:00&lt;00:00, 59.1MB/s]Downloading data: 100%|##########| 26.4M/26.4M [00:00&lt;00:00, 56.8MB/s]\nDownloading data files:  25%|##5       | 1/4 [00:02&lt;00:07,  2.40s/it]\nDownloading data:   0%|          | 0.00/29.5k [00:00&lt;?, ?B/s]Downloading data: 100%|##########| 29.5k/29.5k [00:00&lt;00:00, 2.99MB/s]\nDownloading data files:  50%|#####     | 2/4 [00:03&lt;00:02,  1.41s/it]\nDownloading data:   0%|          | 0.00/4.42M [00:00&lt;?, ?B/s]\nDownloading data:  37%|###7      | 1.64M/4.42M [00:00&lt;00:00, 16.4MB/s]Downloading data: 100%|##########| 4.42M/4.42M [00:00&lt;00:00, 31.3MB/s]\nDownloading data files:  75%|#######5  | 3/4 [00:04&lt;00:01,  1.51s/it]\nDownloading data:   0%|          | 0.00/5.15k [00:00&lt;?, ?B/s]Downloading data: 100%|##########| 5.15k/5.15k [00:00&lt;00:00, 15.7MB/s]\nDownloading data files: 100%|##########| 4/4 [00:05&lt;00:00,  1.19s/it]Downloading data files: 100%|##########| 4/4 [00:05&lt;00:00,  1.36s/it]\nExtracting data files:   0%|          | 0/4 [00:00&lt;?, ?it/s]Extracting data files:  25%|##5       | 1/4 [00:00&lt;00:00,  3.17it/s]Extracting data files: 100%|##########| 4/4 [00:00&lt;00:00, 10.79it/s]\nGenerating train split:   0%|          | 0/60000 [00:00&lt;?, ? examples/s]Generating train split:   0%|          | 1/60000 [00:00&lt;3:04:15,  5.43 examples/s]Generating train split:   1%|1         | 605/60000 [00:00&lt;00:22, 2637.95 examples/s]Generating train split:   2%|1         | 1174/60000 [00:00&lt;00:15, 3807.17 examples/s]Generating train split:   3%|2         | 1793/60000 [00:00&lt;00:12, 4648.75 examples/s]Generating train split:   4%|3         | 2382/60000 [00:00&lt;00:11, 5062.68 examples/s]Generating train split:   5%|5         | 3000/60000 [00:00&lt;00:10, 5357.95 examples/s]Generating train split:   6%|6         | 3619/60000 [00:00&lt;00:10, 5614.02 examples/s]Generating train split:   7%|7         | 4211/60000 [00:00&lt;00:09, 5703.58 examples/s]Generating train split:   8%|8         | 4828/60000 [00:00&lt;00:09, 5845.78 examples/s]Generating train split:  10%|9         | 5731/60000 [00:01&lt;00:09, 5912.84 examples/s]Generating train split:  11%|#1        | 6637/60000 [00:01&lt;00:08, 5956.33 examples/s]Generating train split:  13%|#2        | 7544/60000 [00:01&lt;00:08, 5984.45 examples/s]Generating train split:  14%|#4        | 8448/60000 [00:01&lt;00:08, 5995.56 examples/s]Generating train split:  16%|#5        | 9353/60000 [00:01&lt;00:08, 6004.58 examples/s]Generating train split:  17%|#6        | 9975/60000 [00:01&lt;00:08, 6053.00 examples/s]Generating train split:  18%|#8        | 10882/60000 [00:01&lt;00:08, 6047.45 examples/s]Generating train split:  20%|#9        | 11788/60000 [00:02&lt;00:07, 6040.38 examples/s]Generating train split:  21%|##1       | 12692/60000 [00:02&lt;00:07, 6033.67 examples/s]Generating train split:  22%|##2       | 13312/60000 [00:02&lt;00:07, 6014.95 examples/s]Generating train split:  23%|##3       | 13936/60000 [00:02&lt;00:07, 6067.89 examples/s]Generating train split:  25%|##4       | 14844/60000 [00:02&lt;00:07, 6058.94 examples/s]Generating train split:  26%|##6       | 15751/60000 [00:02&lt;00:07, 6052.31 examples/s]Generating train split:  28%|##7       | 16661/60000 [00:02&lt;00:07, 6054.29 examples/s]Generating train split:  29%|##9       | 17566/60000 [00:03&lt;00:07, 6044.50 examples/s]Generating train split:  31%|###       | 18467/60000 [00:03&lt;00:06, 6030.00 examples/s]Generating train split:  32%|###2      | 19368/60000 [00:03&lt;00:06, 6020.40 examples/s]Generating train split:  33%|###3      | 19990/60000 [00:03&lt;00:06, 6062.48 examples/s]Generating train split:  35%|###4      | 20886/60000 [00:03&lt;00:06, 6031.80 examples/s]Generating train split:  36%|###6      | 21778/60000 [00:03&lt;00:06, 6000.94 examples/s]Generating train split:  38%|###7      | 22686/60000 [00:03&lt;00:06, 6013.88 examples/s]Generating train split:  39%|###9      | 23595/60000 [00:04&lt;00:06, 6023.82 examples/s]Generating train split:  41%|####      | 24506/60000 [00:04&lt;00:05, 6035.31 examples/s]Generating train split:  42%|####2     | 25405/60000 [00:04&lt;00:05, 6021.88 examples/s]Generating train split:  44%|####3     | 26309/60000 [00:04&lt;00:05, 6019.06 examples/s]Generating train split:  45%|####4     | 26932/60000 [00:04&lt;00:05, 6065.76 examples/s]Generating train split:  46%|####6     | 27839/60000 [00:04&lt;00:05, 6057.32 examples/s]Generating train split:  48%|####7     | 28740/60000 [00:04&lt;00:05, 6038.13 examples/s]Generating train split:  49%|####9     | 29649/60000 [00:05&lt;00:05, 6040.42 examples/s]Generating train split:  51%|#####     | 30555/60000 [00:05&lt;00:04, 6038.37 examples/s]Generating train split:  52%|#####2    | 31461/60000 [00:05&lt;00:04, 6036.28 examples/s]Generating train split:  54%|#####3    | 32360/60000 [00:05&lt;00:04, 6022.65 examples/s]Generating train split:  55%|#####4    | 32982/60000 [00:05&lt;00:04, 6065.09 examples/s]Generating train split:  56%|#####6    | 33883/60000 [00:05&lt;00:04, 6042.15 examples/s]Generating train split:  58%|#####7    | 34784/60000 [00:05&lt;00:04, 6027.12 examples/s]Generating train split:  59%|#####9    | 35684/60000 [00:06&lt;00:04, 6016.15 examples/s]Generating train split:  61%|######    | 36588/60000 [00:06&lt;00:03, 6017.08 examples/s]Generating train split:  62%|######2   | 37493/60000 [00:06&lt;00:03, 6020.32 examples/s]Generating train split:  64%|######3   | 38398/60000 [00:06&lt;00:03, 6022.78 examples/s]Generating train split:  66%|######5   | 39311/60000 [00:06&lt;00:03, 6024.56 examples/s]Generating train split:  67%|######6   | 39932/60000 [00:06&lt;00:03, 6063.46 examples/s]Generating train split:  68%|######8   | 40841/60000 [00:06&lt;00:03, 6059.71 examples/s]Generating train split:  70%|######9   | 41744/60000 [00:07&lt;00:03, 6042.62 examples/s]Generating train split:  71%|#######1  | 42652/60000 [00:07&lt;00:02, 6041.98 examples/s]Generating train split:  73%|#######2  | 43555/60000 [00:07&lt;00:02, 6031.92 examples/s]Generating train split:  74%|#######4  | 44464/60000 [00:07&lt;00:02, 6037.69 examples/s]Generating train split:  76%|#######5  | 45364/60000 [00:07&lt;00:02, 6022.57 examples/s]Generating train split:  77%|#######6  | 45989/60000 [00:07&lt;00:02, 6071.31 examples/s]Generating train split:  78%|#######8  | 46895/60000 [00:07&lt;00:02, 6059.60 examples/s]Generating train split:  80%|#######9  | 47794/60000 [00:08&lt;00:02, 6036.77 examples/s]Generating train split:  81%|########1 | 48704/60000 [00:08&lt;00:01, 6042.21 examples/s]Generating train split:  82%|########2 | 49313/60000 [00:08&lt;00:01, 6025.98 examples/s]Generating train split:  83%|########3 | 49935/60000 [00:08&lt;00:01, 6071.85 examples/s]Generating train split:  85%|########4 | 50836/60000 [00:08&lt;00:01, 6045.17 examples/s]Generating train split:  86%|########6 | 51737/60000 [00:08&lt;00:01, 6031.97 examples/s]Generating train split:  88%|########7 | 52635/60000 [00:08&lt;00:01, 6013.61 examples/s]Generating train split:  89%|########9 | 53542/60000 [00:09&lt;00:01, 6020.33 examples/s]Generating train split:  91%|######### | 54443/60000 [00:09&lt;00:00, 6010.59 examples/s]Generating train split:  92%|#########2| 55349/60000 [00:09&lt;00:00, 6016.27 examples/s]Generating train split:  93%|#########3| 55969/60000 [00:09&lt;00:00, 6054.60 examples/s]Generating train split:  95%|#########4| 56872/60000 [00:09&lt;00:00, 6040.91 examples/s]Generating train split:  96%|#########6| 57774/60000 [00:09&lt;00:00, 6030.02 examples/s]Generating train split:  98%|#########7| 58676/60000 [00:09&lt;00:00, 6021.55 examples/s]Generating train split:  99%|#########9| 59574/60000 [00:10&lt;00:00, 6008.55 examples/s]Generating train split: 100%|##########| 60000/60000 [00:10&lt;00:00, 5920.43 examples/s]\nGenerating test split:   0%|          | 0/10000 [00:00&lt;?, ? examples/s]Generating test split:   6%|5         | 575/10000 [00:00&lt;00:01, 5731.79 examples/s]Generating test split:  12%|#1        | 1167/10000 [00:00&lt;00:01, 5836.07 examples/s]Generating test split:  18%|#7        | 1789/10000 [00:00&lt;00:01, 6010.28 examples/s]Generating test split:  27%|##7       | 2700/10000 [00:00&lt;00:01, 6034.39 examples/s]Generating test split:  33%|###3      | 3310/10000 [00:00&lt;00:01, 5995.11 examples/s]Generating test split:  39%|###9      | 3933/10000 [00:00&lt;00:01, 6064.38 examples/s]Generating test split:  48%|####8     | 4831/10000 [00:00&lt;00:00, 6031.51 examples/s]Generating test split:  57%|#####7    | 5739/10000 [00:00&lt;00:00, 6035.59 examples/s]Generating test split:  66%|######6   | 6650/10000 [00:01&lt;00:00, 6042.65 examples/s]Generating test split:  76%|#######5  | 7550/10000 [00:01&lt;00:00, 6026.25 examples/s]Generating test split:  85%|########4 | 8458/10000 [00:01&lt;00:00, 6030.75 examples/s]Generating test split:  94%|#########3| 9361/10000 [00:01&lt;00:00, 6024.84 examples/s]Generating test split: 100%|#########9| 9986/10000 [00:01&lt;00:00, 6073.81 examples/s]Generating test split: 100%|##########| 10000/10000 [00:01&lt;00:00, 6010.16 examples/s]\n/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n\n\n\nlearn.fit(n_epochs=5)\n\n\n\n\n\n\n\n\naccuracy\nloss\nepoch\ntrain\n\n\n\n\n0.590\n1.390\n0\ntrain\n\n\n0.662\n0.928\n0\neval\n\n\n0.710\n0.814\n1\ntrain\n\n\n0.724\n0.748\n1\neval\n\n\n0.751\n0.699\n2\ntrain\n\n\n0.749\n0.710\n2\neval\n\n\n0.777\n0.638\n3\ntrain\n\n\n0.780\n0.621\n3\neval\n\n\n0.791\n0.597\n4\ntrain\n\n\n0.781\n0.608\n4\neval\n\n\n\n\n\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n\n\n\n\n\nTrainLearner is a Learner with predict, get_loss, backward, step and zero_grad already implemented. This is the same as a plain Learner with a TrainCB.\n\nsource\n\n\nTrainLearner\n\n TrainLearner (model, dls=(0,), loss_func=&lt;function mse_loss&gt;, lr=0.1,\n               cbs=None, opt_func=&lt;class 'torch.optim.sgd.SGD'&gt;)\n\nInitialize self. See help(type(self)) for accurate signature.\nMomentumLearner is a TrainLearner using Momentum instead of vanilla SGD.\n\nsource\n\n\nMomentumLearner\n\n MomentumLearner (model, dls, loss_func, lr=None, cbs=None,\n                  opt_func=&lt;class 'torch.optim.sgd.SGD'&gt;, mom=0.85)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nsource\n\n\nLRFinderCB\n\n LRFinderCB (gamma=1.3, max_mult=3)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nsource\n\n\nshow_doc\n\n show_doc (sym, renderer=None, name:Optional[str]=None, title_level:int=3)\n\nShow signature and docstring for sym\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsym\n\n\nSymbol to document\n\n\nrenderer\nNoneType\nNone\nOptional renderer (defaults to markdown)\n\n\nname\nstr | None\nNone\nOptionally override displayed name of sym\n\n\ntitle_level\nint\n3\nHeading level to use for symbol name\n\n\n\n\ndls = DataLoaders.from_dd(tds, bs, num_workers=4)\nmodel = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))\n\nlearn = TrainLearner(model, dls, loss_func=F.cross_entropy)\nlearn.lr_find()\n\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n[W ParallelNative.cpp:230] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n\n\n\n\n\n\nimport nbdev; nbdev.nbdev_export()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "miniai",
    "section": "",
    "text": "This repository is built from the miniai repository create by Jeremy Howard, Jonathan Whitaker and Tanishq Abraham. An overview of the course can be found here\nThe course github repository is here\nThe original miniai library is great but is tied to the course. We have found it a very powerful and light framework that is easy to use, understand and build upon, which is the purpose of this repository. In particular it is easy to add write and add new callbacks that enhance the capability of the framework. This repository in intended to organise the framework is a more functional manner and to provide a home for additional callbacks and other additions. More details will be added as the content is developed"
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "miniai",
    "section": "Install",
    "text": "Install\nNote that this is not setup on pip as yet. To install clone the libary and do a pip install -e ‘.[dev]’"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "miniai",
    "section": "How to use",
    "text": "How to use\nFill me in please! Don’t forget code examples:\n\n1+1\n\n2"
  }
]